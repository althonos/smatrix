[
   {
      "name": "Parallel run options",
      "options": [
         {
            "name": "account",
            "short": "A",
            "help": "charge job to specified account",
            "meta": "name"
         },
         {
            "name": "bb",
            "meta": "spec",
            "help": "burst buffer specifications"
         },
         {
            "name": "bbf",
            "meta": "filename",
            "help": "burst buffer specification file"
         },
         {
            "name": "begin",
            "short": "b",
            "meta": "time",
            "help": "defer job until HH:MM mm/dd/yy"
         },
         {
            "name": "comment",
            "meta": "comment",
            "help": "arbitrary comment"
         },
         {
            "name": "cpu-freq",
            "meta": "min[-max[:gov]]",
            "help": "requested cpu frequency (and governor)"
         },
         {
            "name": "cpus-per-task",
            "short": "c",
            "meta": "ncpus",
            "help": "number of cpus requested per task"
         },
         {
            "name": "dependency",
            "short": "d",
            "meta": "type:jobid",
            "help": "defer job until condition on jobid is satisfied"
         },
         {
            "name": "deadline",
            "meta": "time",
            "help": "remove the job if no ending possible before this deadline (start > (deadline - time[-min]))"
         },
         {
            "name": "delay-boot",
            "meta": "mins",
            "help": "delay boot for desired node features"
         },
         {
            "name": "chdir",
            "short": "D",
            "meta": "directory",
            "help": "set working directory for batch script"
         },
         {
            "name": "error",
            "short": "e",
            "meta": "err",
            "help": "file for batch script's standard error"
         },
         {
            "name": "export",
            "meta": "names",
            "nargs": "?",
            "help": "specify environment variables to export"
         },
         {
            "name": "export-file",
            "meta": "file|fd",
            "help": "specifiy environment variables file or file descriptor to export"
         },
         {
            "name": "get-user-env",
            "help": "load environment from local cluster"
         },
         {
            "name": "gid",
            "meta": "group_id",
            "help": "group ID to run job as (user root only)"
         },
         {
            "name": "gres",
            "meta": "list",
            "help": "required generic resources"
         },
         {
            "name": "gres-flags",
            "meta": "opts",
            "help": "flags related to GRES management"
         },
         {
            "name": "hold",
            "short": "H",
            "help": "submit job in held state"
         },
         {
            "name": "ignore-pbs",
            "help": "ignore #PBS options in the batch script"
         },
         {
            "name": "input",
            "short": "i",
            "meta": "in",
            "help": "file for batch script's standard input"
         },
         {
            "name": "job-name",
            "short": "J",
            "meta": "jobname",
            "help": "name of job"
         },
         {
            "name": "no-kill",
            "short": "k",
            "help": "do not kill job on node failure"
         },
         {
            "name": "licenses",
            "short": "L",
            "meta": "names",
            "help": "required license, comma separated"
         },
         {
            "name": "clusters",
            "short": "M",
            "meta": "names",
            "help": "Comma separated list of clusters to issue commands to. Default is current cluster. Name of 'all' will submit to run on all clusters. NOTE: SlurmDBD must be up."
         },
         {
            "name": "distribution",
            "short": "m",
            "meta": "type",
            "help": "distribution method for processes to nodes (type = block|cyclic|arbitrary)"
         },
         {
            "name": "mail-type",
            "meta": "type",
            "help": "notify on state change: BEGIN, END, FAIL or ALL"
         },
         {
            "name": "mail-user",
            "meta": "user",
            "help": "who to send email notification for job state changes"
         },
         {
            "name": "mcs-label",
            "meta": "mcs",
            "help": "mcs label if mns plugin / mcs group is used"
         },
         {
            "name": "ntasks",
            "short": "n",
            "meta": "ntasks",
            "help": "number of tasks to run"
         },
         {
            "name": "nice",
            "meta": "value",
            "nargs": "?",
            "help": "decrease scheduling priority by value"
         },
         {
            "name": "no-requeue",
            "help": "if set, do not permit the job to be requeued"
         },
         {
            "name": "ntasks-per-node",
            "meta": "n",
            "help": "number of tasks to invoke on each node"
         },
         {
            "name": "nodes",
            "short": "N",
            "meta": "min[-max]",
            "help": "number of nodes on which to run"
         },
         {
            "name": "output",
            "short": "o",
            "meta": "out",
            "help": "file for batch script's standard output"
         },
         {
            "name": "overcommit",
            "short": "O",
            "help": "overcommit resources"
         },
         {
            "name": "partition",
            "short": "p",
            "meta": "partition",
            "help": "partition requested"
         },
         {
            "name": "power",
            "meta": "flags",
            "help": "power management options"
         },
         {
            "name": "priority",
            "meta": "value",
            "help": "set the priority of the job to value"
         },
         {
            "name": "profile",
            "meta": "value",
            "help": "enable acct_gather_profile for detailed data. value is all or none or any combination of energy, lustre, network or task"
         },
         {
            "name": "propagate",
            "meta": "rlimits",
            "nargs": "?",
            "help": "propagate all [or specific list of] rlimits"
         },
         {
            "name": "qos",
            "short": "q",
            "meta": "qos",
            "help": "quality of service"
         },
         {
            "name": "quiet",
            "short": "Q",
            "help": "quiet mode (suppress informational messages)",
            "transmit": false
         },
         {
            "name": "reboot",
            "help": "reboot compute nodes before starting job"
         },
         {
            "name": "requeue",
            "help": "if set, permit the job to be requeued"
         },
         {
            "name": "oversubscribe",
            "short": "s",
            "help": "over subscribe resources with other jobs"
         },
         {
            "name": "core-spec",
            "short": "S",
            "meta": "cores",
            "help": "count of reserved cores"
         },
         {
            "name": "signal",
            "meta": "[B:]num[@time]",
            "help": "send signal when time limit within time seconds"
         },
         {
            "name": "spread-job",
            "help": "spread job across as many nodes as possible"
         },
         {
            "name": "switches",
            "meta": "max-switches{@max-time-to-wait}",
            "help": "optimum switches and max time to wait for optimum"
         },
         {
            "name": "thread-spec",
            "meta": "threads",
            "help": "count of reserved threads"
         },
         {
            "name": "time",
            "short": "t",
            "meta": "minutes",
            "help": "time limit"
         },
         {
            "name": "time-min",
            "meta": "minutes",
            "help": "minimum time limit (if distinct)"
         },
         {
            "name": "uid",
            "meta": "user_id",
            "help": "user ID to run job as (user root only)"
         },
         {
            "name": "use-min-nodes",
            "help": "if a range of node counts is given, prefer the smaller count"
         },
         {
            "name": "verbose",
            "short": "v",
            "help": "verbose mode (multiple -v's increase verbosity)",
            "nargs": "+",
            "transmit": false
         },
         {
            "name": "wait",
            "short": "W",
            "help": "wait for completion of submitted job"
         },
         {
            "name": "wckey",
            "meta": "wckey",
            "help": "wckey to run job under"
         },
         {
            "name": "wrap",
            "meta": "command",
            "nargs": "?",
            "help": "wrap command string in a sh script and submit",
            "transmit": false
         }
      ]
   },
   {
      "name": "Constraint options",
      "options": [
         {
            "name": "cluster-constraint",
            "meta": "list",
            "help": "list specify a list of cluster constraints"
         },
         {
            "name": "contiguous",
            "help": "demand a contiguous range of nodes"
         },
         {
            "name": "constraint",
            "meta": "list",
            "short": "C",
            "help": "specificy a list of constraints"
         },
         {
            "name": "nodefile",
            "short": "F",
            "meta": "filename",
            "help": "request a specific list of hosts"
         },
         {
            "name": "mem",
            "meta": "MB",
            "help": "minimum amount of real memory"
         },
         {
            "name": "mincpus",
            "meta": "n",
            "help": "minimum number of logical processors (threads) per node"
         },
         {
            "name": "reservation",
            "meta": "name",
            "help": "allocate resources from named reservation"
         },
         {
            "name": "tmp",
            "meta": "MB",
            "help": "minimum amount of temporary disk"
         },
         {
            "name": "nodelist",
            "short": "w",
            "meta": "hosts",
            "help": "request a specific list of hosts"
         },
         {
            "name": "exclude",
            "short": "x",
            "meta": "hosts",
            "help": "exclude a specific list of hosts"
         }
      ]
   },
   {
      "name": "Consumable resources related options",
      "options": [
         {
            "name": "exclusive",
            "meta": "user",
            "nargs": "?",
            "help": "allocate nodes in exclusive mode when cpu consumable resource is enabled"
         },
         {
            "name": "mem-per-cpu",
            "meta": "MB",
            "help": "maximum amount of real memory per allocated cpu required by the job. (--mem >= --mem-per-cpu if --mem specified)"
         }
      ]
   },
   {
      "name": "Affinity/Multi-core options: (when the task/affinity plugin is enabled)",
      "options": [
         {
            "name": "extra-node-info",
            "short": "B",
            "meta": "S[:C[:T]]",
            "help": "Expands to:"
         },
         {
            "name": "sockets-per-node",
            "meta": "S",
            "help": "number of sockets per node to allocate"
         },
         {
            "name": "cores-per-socket",
            "meta": "C",
            "help": "number of cores per socket to allocate"
         },
         {
            "name": "threads-per-core",
            "meta": "T",
            "help": "number of threads per core to allocate"
         },
         {
            "name": "ntasks-per-core",
            "meta": "n",
            "help": "number of tasks to invoke on each core"
         },
         {
            "name": "ntasks-per-socket",
            "meta": "n",
            "help": "number of tasks to invoke on each socket"
         },
         {
            "name": "hint",
            "meta": "hint",
            "help": "bind tasks according to application hints (see \"--hint=help\" for options)"
         },
         {
            "name": "mem-bind",
            "meta": "mem",
            "help": "bind memory to locality domains (ldom) (see \"--mem-bind=help\" for options)"
         }
      ]
   },
   {
      "name": "GPU scheduling options",
      "options": [
         {
            "name": "cpus-per-gpu",
            "meta": "n",
            "help": "number of CPUs required per allocated GPU"
         },
         {
            "name": "gpus",
            "short": "G",
            "meta": "n",
            "help": "count of GPUs required for the job"
         },
         {
            "name": "gpu-bind",
            "meta": "...",
            "help": "task to gpu binding options"
         },
         {
            "name": "gpu-freq",
            "meta": "...",
            "help": "frequency and voltage of GPUs"
         },
         {
            "name": "gpus-per-node",
            "meta": "n",
            "help": "number of GPUs required per allocated node"
         },
         {
            "name": "gpus-per-socket",
            "meta": "n",
            "help": "number of GPUs required per allocated socket"
         },
         {
            "name": "gpus-per-task",
            "meta": "n",
            "help": "number of GPUs required per spawned task"
         },
         {
            "name": "mem-per-gpu",
            "meta": "n",
            "help": "real memory required per allocated GPU"
         }
      ]
   }
]
